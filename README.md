# DFA-Instruct
An instruction-following dataset for interactive deepfake analysis in ICASSP 2025 accepted paper **[Towards Interactive Deepfake Analysis](https://arxiv.org/abs/2501.01164)**.


- Responses generated by the interactive deepfake analysis system, DFA-GPT
 <img src="https://github.com/lxq1000/DFA-Instruct/blob/main/pictures/main.png" alt="Image" width="400">

 
- Data construction process for DFA-Instruct
 <img src="https://github.com/lxq1000/DFA-Instruct/blob/main/pictures/main2.png" alt="Image" width="400">

 
- Overall architecture of the DFA-GPT
 <img src="https://github.com/lxq1000/DFA-Instruct/blob/main/pictures/main3.png" alt="Image" width="400">


 **<p align="justify"> Abstract:** *Existing deepfake analysis methods are primarily based on discriminative models, which significantly limit their application scenarios. 
This paper aims to explore interactive deepfake analysis by performing instruction tuning on multi-modal large language models (MLLMs). 
This will face challenges such as the lack of datasets and benchmarks, and low training efficiency. To address these issues, we introduce (1) a GPT-assisted data construction process resulting in an instruction-following dataset called DFA-Instruct, (2) a benchmark named DFA-Bench, designed to comprehensively evaluate the capabilities of MLLMs in deepfake detection, deepfake classification, and artifact description, and (3) construct an interactive deepfake analysis system called DFA-GPT, as a strong baseline for the community, with the Low-Rank Adaptation (LoRA) module.* </p>



